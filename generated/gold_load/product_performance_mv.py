# Generated by LakehousePlumber
# Pipeline: gold_load
# FlowGroup: product_performance_mv
# Generated: 2025-07-16T10:03:28.376658

from pyspark.sql import DataFrame
import dlt

# Pipeline Configuration
PIPELINE_ID = "gold_load"
FLOWGROUP_ID = "product_performance_mv"

# ============================================================================
# SOURCE VIEWS
# ============================================================================

@dlt.view()
def v_product_performance_mv_sql():
    """SQL source: product_performance_mv_sql"""
    df = spark.sql("""SELECT
  p.part_id,
  p.name as product_name,
  p.manufacturer,
  p.brand,
  p.type,
  COUNT(DISTINCT l.order_id) as orders_count,
  SUM(l.quantity) as total_quantity_sold,
  SUM(l.extended_price) as total_revenue,
  AVG(l.extended_price / l.quantity) as avg_unit_price,
  SUM(l.extended_price * l.discount) as total_discount_given,
  AVG(l.discount) as avg_discount_rate,
  DATE_TRUNC('month', o.order_date) as month
FROM acmi_edw_dev.edw_silver.lineitem_fct l
JOIN acmi_edw_dev.edw_silver.orders_fct o ON l.order_id = o.order_id
JOIN acmi_edw_dev.edw_silver.part_dim p ON l.part_id = p.part_id
  AND o.order_date >= p.__start_at
  AND (o.order_date < p.__end_at OR p.__end_at IS NULL)
GROUP BY p.part_id, p.name, p.manufacturer, p.brand, p.type, DATE_TRUNC('month', o.order_date)
""")

    return df


# ============================================================================
# TARGET TABLES
# ============================================================================

@dlt.table(
    name="acmi_edw_dev.edw_gold.product_performance_mv",
    comment="Materialized view: product_performance_mv",
    table_properties={})
def product_performance_mv():
    """Write to acmi_edw_dev.edw_gold.product_performance_mv from multiple sources"""
    # Materialized views use batch processing
    df = spark.read.table("v_product_performance_mv_sql")

    return df
