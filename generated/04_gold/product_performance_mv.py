# Generated by LakehousePlumber
# Pipeline: gold_load
# FlowGroup: product_performance_mv
# Generated: 2025-07-14T15:38:47.857647

from pyspark.sql import DataFrame
import dlt

# Pipeline Configuration
PIPELINE_ID = "product_performance_mv"
PIPELINE_GROUP = "gold_load"

# ============================================================================
# SOURCE VIEWS
# ============================================================================


@dlt.view()
def v_product_performance_mv_sql():
    """SQL source: product_performance_mv_sql"""
    df = spark.sql(
        """SELECT
  p.part_key,
  p.name as product_name,
  p.manufacturer,
  p.brand,
  p.type,
  COUNT(DISTINCT l.order_key) as orders_count,
  SUM(l.quantity) as total_quantity_sold,
  SUM(l.extended_price) as total_revenue,
  AVG(l.extended_price / l.quantity) as avg_unit_price,
  SUM(l.extended_price * l.discount) as total_discount_given,
  AVG(l.discount) as avg_discount_rate,
  DATE_TRUNC('month', o.order_date) as month
FROM acmi_edw_dev.edw_silver.part_dim p
JOIN acmi_edw_dev.edw_silver.lineitem_fct l ON p.part_key = l.part_key
JOIN acmi_edw_dev.edw_silver.orders_fct o ON l.order_key = o.order_key
GROUP BY p.part_key, p.name, p.manufacturer, p.brand, p.type, DATE_TRUNC('month', o.order_date)
"""
    )

    return df


# ============================================================================
# TARGET TABLES
# ============================================================================


@dlt.table(
    name="acmi_edw_dev.edw_gold.product_performance_mv",
    comment="Materialized view: product_performance_mv",
    table_properties={},
)
def product_performance_mv():
    """Write to acmi_edw_dev.edw_gold.product_performance_mv from multiple sources"""
    # Materialized views use batch processing
    df = spark.read.table("v_product_performance_mv_sql")

    return df
