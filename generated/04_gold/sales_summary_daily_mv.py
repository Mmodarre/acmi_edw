# Generated by LakehousePlumber
# Pipeline: gold_load
# FlowGroup: sales_summary_daily_mv
# Generated: 2025-07-14T15:38:47.836824

from pyspark.sql import DataFrame
import dlt

# Pipeline Configuration
PIPELINE_ID = "sales_summary_daily_mv"
PIPELINE_GROUP = "gold_load"

# ============================================================================
# SOURCE VIEWS
# ============================================================================


@dlt.view()
def v_sales_summary_daily_mv_sql():
    """SQL source: sales_summary_daily_mv_sql"""
    df = spark.sql(
        """SELECT
  order_date,
  COUNT(DISTINCT o.order_id) as total_orders,
  COUNT(DISTINCT c.customer_id) as unique_customers,
  SUM(total_price) as total_revenue,
  AVG(total_price) as avg_order_value,
  SUM(CASE WHEN order_status = 'F' THEN 1 ELSE 0 END) as fulfilled_orders,
  SUM(CASE WHEN order_status = 'O' THEN 1 ELSE 0 END) as open_orders
FROM acmi_edw_dev.edw_silver.orders_fct o
JOIN acmi_edw_dev.edw_silver.customer_dim c ON o.customer_id = c.customer_id
GROUP BY order_date
"""
    )

    return df


# ============================================================================
# TARGET TABLES
# ============================================================================


@dlt.table(
    name="acmi_edw_dev.edw_gold.sales_summary_daily_mv",
    comment="Materialized view: sales_summary_daily_mv",
    table_properties={},
)
def sales_summary_daily_mv():
    """Write to acmi_edw_dev.edw_gold.sales_summary_daily_mv from multiple sources"""
    # Materialized views use batch processing
    df = spark.read.table("v_sales_summary_daily_mv_sql")

    return df
