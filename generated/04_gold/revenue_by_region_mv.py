# Generated by LakehousePlumber
# Pipeline: gold_load
# FlowGroup: revenue_by_region_mv
# Generated: 2025-07-14T15:51:27.369657

from pyspark.sql import DataFrame
import dlt

# Pipeline Configuration
PIPELINE_ID = "revenue_by_region_mv"
PIPELINE_GROUP = "gold_load"

# ============================================================================
# SOURCE VIEWS
# ============================================================================


@dlt.view()
def v_revenue_by_region_mv_sql():
    """SQL source: revenue_by_region_mv_sql"""
    df = spark.sql(
        """SELECT
    r.name as region_name,
    n.name as nation_name,
    DATE_TRUNC('month', o.order_date) as month,
    SUM(o.total_price) as region_revenue,
    COUNT(DISTINCT o.order_id) as region_orders,
    COUNT(DISTINCT c.customer_id) as region_customers
FROM acmi_edw_dev.edw_silver.orders_fct o
JOIN acmi_edw_dev.edw_silver.customer_dim c ON o.customer_id = c.customer_id
JOIN acmi_edw_dev.edw_silver.nation_dim n ON c.nation_id = n.nation_id
JOIN acmi_edw_dev.edw_silver.region_dim r ON n.region_id = r.region_id
GROUP BY r.name, n.name, DATE_TRUNC('month', o.order_date)
"""
    )

    return df


# ============================================================================
# TARGET TABLES
# ============================================================================


@dlt.table(
    name="acmi_edw_dev.edw_gold.revenue_by_region_mv",
    comment="Materialized view: revenue_by_region_mv",
    table_properties={},
)
def revenue_by_region_mv():
    """Write to acmi_edw_dev.edw_gold.revenue_by_region_mv from multiple sources"""
    # Materialized views use batch processing
    df = spark.read.table("v_revenue_by_region_mv_sql")

    return df
